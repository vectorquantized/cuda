{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmGUFN87XQP6",
        "outputId": "e585b9ea-ebcd-487b-ec46-5b218a87ceb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile add.cpp\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "// function to add the elements of two arrays\n",
        "void add(int n, float *x, float *y)\n",
        "{\n",
        "  for (int i = 0; i < n; i++)\n",
        "      y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int N = 1<<20; // 1M elements\n",
        "\n",
        "  float *x = new float[N];\n",
        "  float *y = new float[N];\n",
        "\n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the CPU\n",
        "  add(N, x, y);\n",
        "\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  delete [] x;\n",
        "  delete [] y;\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y libopencv-dev python3-opencv"
      ],
      "metadata": {
        "id": "ktT-UaC9Dapg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "g++ add.cpp -o add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df0k0zehXh4f",
        "outputId": "b03f2b0c-6a8d-4785-f514-b1c032b8c811"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./add"
      ],
      "metadata": {
        "id": "Wkbs5Y3ZX4ul",
        "outputId": "6e3acd77-f678-4935-a36f-c0ddad4b58fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/utils.h\n",
        "\n",
        "#ifndef UTILS_H\n",
        "#define UTILS_H\n",
        "\n",
        "#include <math.h>\n",
        "#include <opencv2/opencv.hpp>\n",
        "\n",
        "namespace matrix {\n",
        "// Function to compare two matrices\n",
        "inline bool compare_matrices(const float* mat1, const float* mat2, int rows, int cols, float epsilon = 1e-4) {\n",
        "    for (int i = 0; i < rows * cols; ++i) {\n",
        "        if (std::abs(mat1[i] - mat2[i]) > epsilon) {\n",
        "            return false;\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "}\n",
        "\n",
        "namespace utils{\n",
        "// Function to compare two matrices\n",
        "inline bool compare_vectors(const float* vec1, const float* vec2, int size, float epsilon = 1e-4) {\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        if (std::abs(vec1[i] - vec2[i]) > epsilon) {\n",
        "            return false;\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "}\n",
        "\n",
        "namespace imageio {\n",
        "inline cv::Mat readImage(std::string image_path) {\n",
        "    cv::Mat image = cv::imread(image_path, cv::IMREAD_COLOR);\n",
        "\n",
        "    if (image.empty()) {\n",
        "        std::cerr << \"Could not open or find the image at \" << image_path << std::endl;\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    return image;\n",
        "}\n",
        "\n",
        "inline cv::Mat toFloatMat(const cv::Mat& mat) {\n",
        "    cv::Mat float_mat;\n",
        "    if (mat.type() != CV_32F) {\n",
        "        mat.convertTo(float_mat, CV_32F);\n",
        "    } else {\n",
        "        float_mat = mat;\n",
        "    }\n",
        "    return float_mat;\n",
        "}\n",
        "\n",
        "inline void matToFloatArray(const cv::Mat& mat, float* out, size_t size) {\n",
        "    cv::Mat floatMat = toFloatMat(mat);\n",
        "    std::memcpy(out, floatMat.data, size * sizeof(float));\n",
        "}\n",
        "\n",
        "inline cv::Mat floatArrayToMat(const float* floatArray, int width, int height, int channels) {\n",
        "    cv::Mat image(height, width, CV_32FC(channels));\n",
        "    std::memcpy(image.data, floatArray, width * height * channels * sizeof(float));\n",
        "    return image;\n",
        "}\n",
        "\n",
        "inline void writeImage(const float* float_array, int width, int height, int num_channels, std::string output_path) {\n",
        "// convert float array to matrix and write to disk.\n",
        "    cv::Mat restored = imageio::floatArrayToMat(float_array, width, height, num_channels);\n",
        "    bool success = cv::imwrite(output_path, restored);\n",
        "    if (!success) {\n",
        "        std::cerr << \"Could not write image to disk at \" << output_path << std::endl;\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "}\n",
        "\n",
        "#endif // UTILS_H%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh9EXkkCA6RP",
        "outputId": "3eae0360-1b42-42c1-bb0b-5ef692bfdeec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing include/utils.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/matrix.h\n",
        "\n",
        "#ifndef MATRIX_H\n",
        "#define MATRIX_H\n",
        "\n",
        "#include <memory>\n",
        "#include <functional>\n",
        "#include <iomanip>\n",
        "\n",
        "struct Matrix {\n",
        "    int height;\n",
        "    int width;\n",
        "    std::unique_ptr<float[]> data;\n",
        "    Matrix(int height_, int width_, std::function<void(float*, int)> init_func)\n",
        "    : height(height_), width(width_), data(std::make_unique<float[]>(height_ * width_)) {\n",
        "        init_func(data.get(), height_ * width_);\n",
        "    }\n",
        "\n",
        "    // copy constructor, deep copies data value.\n",
        "    // reason for this is that we support in-place operations on matrix\n",
        "    // having this just makes it easier to validate the cpu vs gpu implementations.\n",
        "    Matrix(const Matrix& other)\n",
        "    : height(other.height), width(other.width),\n",
        "    data(std::make_unique<float[]>(other.height * other.width)) {\n",
        "        std::copy(other.data.get(), other.data.get() + other.height * other.width, data.get());\n",
        "    }\n",
        "\n",
        "    // TODO: add move semantics\n",
        "\n",
        "    void print() const {\n",
        "        std::cout << std::fixed << std::setprecision(4);\n",
        "        for(int i =0; i < height; ++i) {\n",
        "            for(int j = 0; j < width; ++j) {\n",
        "                std::cout << data[i * width + j] << \" \";\n",
        "            }\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "    }\n",
        "};\n",
        "\n",
        "#endif //MATRIX_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2q_m8kd9nyb",
        "outputId": "a1656c53-529c-4ba8-c97f-3c2776456bf2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting include/matrix.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/init_utils.h\n",
        "\n",
        "#ifndef INIT_UTILS_H\n",
        "#define INIT_UTILS_H\n",
        "\n",
        "#include <random>\n",
        "\n",
        "inline void random_init(float *array, int size) {\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "\n",
        "    std::uniform_real_distribution<> dist(0.0, 1.0);\n",
        "\n",
        "    for(int i=0; i < size; ++i) {\n",
        "        array[i] = dist(gen);\n",
        "    }\n",
        "}\n",
        "\n",
        "#endif // INIT_UTILS_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByP4V82_-D9O",
        "outputId": "7d319ccd-6b54-4e0e-8113-7fcbeef10bb7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting include/init_utils.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/cuda_utils.h\n",
        "\n",
        "#ifndef CUDA_UTILS_H\n",
        "#define CUDA_UTILS_H\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define CUDA_ERROR_CHECK(call)  { \\\n",
        "    cudaError_t error = call; \\\n",
        "    if (error != cudaSuccess) { \\\n",
        "        fprintf(stderr, \"CUDA error in file '%s' in line %i.%s \\n\", \\\n",
        "                __FILE__, __LINE__, cudaGetErrorString(error)); \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    }}\n",
        "\n",
        "#define TIMED_CUDA_FUNCTION() CudaEventTimer(__FUNCTION__)\n",
        "\n",
        "class CudaEventTimer {\n",
        "\n",
        "public:\n",
        "    CudaEventTimer(const char* function_name):\n",
        "    function_name_(function_name) {\n",
        "        cudaEventCreate(&start_);\n",
        "        cudaEventCreate(&stop_);\n",
        "        cudaEventRecord(start_);\n",
        "    }\n",
        "\n",
        "    ~CudaEventTimer() {\n",
        "        cudaEventRecord(stop_);\n",
        "        cudaEventSynchronize(stop_);\n",
        "        float milliseconds = 0.0f;\n",
        "        cudaEventElapsedTime(&milliseconds, start_, stop_);\n",
        "        std::cout << \"CUDA function \" << function_name_ << \" finished in \" << milliseconds << \" ms\" << std::endl;\n",
        "        cudaEventDestroy(start_);\n",
        "        cudaEventDestroy(stop_);\n",
        "\n",
        "    }\n",
        "private:\n",
        "    const char* function_name_;\n",
        "    cudaEvent_t start_, stop_;\n",
        "};\n",
        "\n",
        "#endif // CUDA_UTILS_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UBfiPWF-Vpz",
        "outputId": "b3f22231-be5f-4b2e-b454-70d70761793f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting include/cuda_utils.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/iming_utils.h\n",
        "\n",
        "#ifndef TIMING_UTILS_H\n",
        "#define TIMING_UTILS_H\n",
        "\n",
        "#include <chrono>\n",
        "#include <string>\n",
        "#include <iostream>\n",
        "\n",
        "#define TIMED_CPU_FUNCTION() timers::FunctionTimer timer(__FUNCTION__)\n",
        "\n",
        "namespace timers {\n",
        "class FunctionTimer {\n",
        "public:\n",
        "    FunctionTimer(std::string function_name) :\n",
        "    function_name_(function_name), start_(std::chrono::high_resolution_clock::now()) {}\n",
        "\n",
        "    ~FunctionTimer() {\n",
        "        auto end = std::chrono::high_resolution_clock::now();\n",
        "        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start_).count();\n",
        "        std::cout << \"CPU function \" << function_name_ << \" finished in \" << duration << \" ms\" <<std::endl;\n",
        "    }\n",
        "\n",
        "private:\n",
        "std::string function_name_;\n",
        "std::chrono::time_point<std::chrono::high_resolution_clock> start_;\n",
        "\n",
        "};\n",
        "}\n",
        "\n",
        "#endif //TIMING_UTILS_H%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QkBMVJw-3Od",
        "outputId": "6d62f342-81d6-4731-cf69-f12e7630b384"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing include/iming_utils.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/cpu_kernels.h\n",
        "\n",
        "#ifndef CPU_KERNELS_H\n",
        "#define CPU_KERNELS_H\n",
        "\n",
        "#include <vector>\n",
        "\n",
        "void matmul_cpu(const float* a, const float* b, float* c, int M, int K, int N);\n",
        "void conv1d_cpu(const std::vector<float>& matrix, const std::vector<float>& conv_mask,\n",
        "                std::vector<float>& output, int mask_width, int width);\n",
        "\n",
        "void conv2d_cpu(const std::vector<float>& matrix, const std::vector<float>& conv_mask,\n",
        "                std::vector<float>& output, int r, int width, int height);\n",
        "\n",
        "void softmax_cpu(float* mat, int M, int N);\n",
        "\n",
        "\n",
        "#endif // CPU_KERNELS_H%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agXtS2Pw-xQ_",
        "outputId": "0dbb8598-dc46-475e-e8e0-fadbe538f7cd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting include/cpu_kernels.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cpu_kernels.cpp\n",
        "\n",
        "#include \"cpu_kernels.h\"\n",
        "#include \"timing_utils.h\"\n",
        "\n",
        "void matmul_cpu(const float* a, const float* b, float* c, int M, int K, int N) {\n",
        "    TIMED_CPU_FUNCTION();\n",
        "    for(int row=0; row < M; ++row) {\n",
        "        for(int col = 0; col < N; ++col) {\n",
        "            float value = 0.0f;\n",
        "            for (int k = 0; k < K; ++k) {\n",
        "                value += a[row * K + k] * b[k * N + col];\n",
        "            }\n",
        "            c[row * N + col] = value;\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPtzGQo3-qVq",
        "outputId": "27c41215-2aa2-4915-b162-ce60b2b33b55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cpu_kernels.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/gemm.h\n",
        "\n",
        "#ifndef GEMM_H\n",
        "#define GEMM_H\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void gemm_cuda_tiled(const float* __restrict__  A, const float* __restrict__ B, float* C, int M, int K, int N);\n",
        "\n",
        "\n",
        "#endif // GEMM_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRMXnEDw_rqD",
        "outputId": "d1e03ffb-f318-4157-93ea-0124f7de5c88"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting include/gemm.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gemm.cu\n",
        "\n",
        "#include \"timing_utils.h\"\n",
        "#include \"init_utils.h\"\n",
        "#include \"matrix.h\"\n",
        "#include \"cuda_utils.h\"\n",
        "#include \"gemm.h\"\n",
        "#include \"cpu_kernels.h\"\n",
        "#include \"utils.h\"\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iomanip>\n",
        "\n",
        "__global__ void gemm_cuda_tiled(const float* __restrict__  a, const float* __restrict__ b,\n",
        "                                float* c, int M, int K, int N) {\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "\n",
        "    int row = by * TILE_WIDTH + ty;\n",
        "    int col = bx * TILE_WIDTH + tx;\n",
        "\n",
        "    __shared__ float a_shared[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ float b_shared[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "    float p_value = 0.0f;\n",
        "    for(int ph = 0; ph < (K + TILE_WIDTH - 1)/ TILE_WIDTH; ++ph) {\n",
        "        if (row < M && ph * TILE_WIDTH + tx < K) {\n",
        "            a_shared[ty][tx] = a[row * K + ph * TILE_WIDTH + tx];\n",
        "        } else {\n",
        "            a_shared[ty][tx] = 0.0f;\n",
        "        }\n",
        "        if(ph * TILE_WIDTH + ty < K && col < N) {\n",
        "            b_shared[ty][tx] = b[(ph * TILE_WIDTH + ty) * N + col];\n",
        "        } else {\n",
        "            b_shared[ty][tx] = 0.0f;\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for(int i = 0; i < TILE_WIDTH; ++i) {\n",
        "            p_value += a_shared[ty][i] * b_shared[i][tx];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(row < M && col < N) {\n",
        "        c[row * N + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "void gemm_kernel_launch(float* mat1_d, float* mat2_d, float* out_d, int M, int K, int N) {\n",
        "    TIMED_CUDA_FUNCTION();\n",
        "    int block_size_x = TILE_WIDTH;\n",
        "    int block_size_y = TILE_WIDTH;\n",
        "\n",
        "    dim3 threads_per_block(block_size_x,\n",
        "                           block_size_y);\n",
        "\n",
        "    dim3 blocks_per_grid((N + block_size_x - 1) / block_size_x,\n",
        "                         (M + block_size_y - 1) / block_size_y);\n",
        "\n",
        "    gemm_cuda_tiled<<<blocks_per_grid, threads_per_block>>>(mat1_d, mat2_d, out_d, M, K, N);\n",
        "    cudaDeviceSynchronize();\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    int M = 128;\n",
        "    int K = 64;\n",
        "    int N = 128;\n",
        "    Matrix mat1_h(M, K, random_init);\n",
        "    Matrix mat2_h(K, N, random_init);\n",
        "    float* out_h = new float[M * N];\n",
        "    float* out_cpu = new float[M * N];\n",
        "    matmul_cpu(mat1_h.data.get(), mat2_h.data.get(), out_cpu, M, K, N);\n",
        "    float *mat1_d, *mat2_d, *out_d;\n",
        "\n",
        "    CUDA_ERROR_CHECK(cudaMalloc((void**) &mat1_d, M * K * sizeof(float)));\n",
        "    CUDA_ERROR_CHECK(cudaMalloc((void**) &mat2_d, K * N * sizeof(float)));\n",
        "    CUDA_ERROR_CHECK(cudaMalloc((void**) &out_d, M * N * sizeof(float)));\n",
        "\n",
        "    CUDA_ERROR_CHECK(cudaMemcpy(mat1_d, mat1_h.data.get(), M * K * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_ERROR_CHECK(cudaMemcpy(mat2_d, mat2_h.data.get(), K * N * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    gemm_kernel_launch(mat1_d, mat2_d, out_d, M, K, N);\n",
        "\n",
        "    CUDA_ERROR_CHECK(cudaMemcpy(out_h, out_d, M * N * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    if (matrix::compare_matrices(out_h, out_cpu, M, N)) {\n",
        "        std::cout << \"CUDA kernel's result matches the CPU result.\" << std::endl;\n",
        "    } else {\n",
        "        std::cerr << \"CUDA kernel's result does NOT match the CPU result.\" << std::endl;\n",
        "    }\n",
        "\n",
        "    delete [] out_h;\n",
        "    delete [] out_cpu;\n",
        "    cudaFree(mat1_d);\n",
        "    cudaFree(mat2_d);\n",
        "    cudaFree(out_d);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "P1GDyYs4X7LR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be69bea6-c0ea-469e-b1c6-5f86ed868113"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting gemm.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -I/usr/include/opencv4 -I./include -L/usr/lib gemm.cu cpu_kernels.cpp -o gemm `pkg-config --cflags --libs opencv4` -diag-suppress=611"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL2yVACy_F6w",
        "outputId": "79d7b31f-987a-4b09-bd4f-634172780bd6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./gemm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyxU_4FzDWxa",
        "outputId": "a41f3de7-dd1b-4578-c7c6-c9b0d52c2e46"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU function matmul_cpu finished in 3 ms\n",
            "CUDA function gemm_kernel_launch finished in 0.002048 ms\n",
            "CUDA kernel's result matches the CPU result.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqyPHrEyDsyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}