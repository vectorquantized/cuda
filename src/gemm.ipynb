{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmGUFN87XQP6",
        "outputId": "16621094-a6f2-45eb-f795-275e258f772d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile add.cpp\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "// function to add the elements of two arrays\n",
        "void add(int n, float *x, float *y)\n",
        "{\n",
        "  for (int i = 0; i < n; i++)\n",
        "      y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int N = 1<<20; // 1M elements\n",
        "\n",
        "  float *x = new float[N];\n",
        "  float *y = new float[N];\n",
        "\n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the CPU\n",
        "  add(N, x, y);\n",
        "\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  delete [] x;\n",
        "  delete [] y;\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y libopencv-dev python3-opencv"
      ],
      "metadata": {
        "id": "ktT-UaC9Dapg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10854f7-cb0d-428f-999c-a5f8761b1f92"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libopencv-dev is already the newest version (4.5.4+dfsg-9ubuntu4+jammy0).\n",
            "Suggested packages:\n",
            "  python-numpy-doc python3-pytest\n",
            "The following NEW packages will be installed:\n",
            "  python3-numpy python3-opencv\n",
            "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 5,272 kB of archives.\n",
            "After this operation, 27.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-numpy amd64 1:1.21.5-1ubuntu22.04.1 [3,467 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-opencv amd64 4.5.4+dfsg-9ubuntu4+jammy0 [1,805 kB]\n",
            "Fetched 5,272 kB in 2s (2,446 kB/s)\n",
            "Selecting previously unselected package python3-numpy.\n",
            "(Reading database ... 123595 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-numpy_1%3a1.21.5-1ubuntu22.04.1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Selecting previously unselected package python3-opencv:amd64.\n",
            "Preparing to unpack .../python3-opencv_4.5.4+dfsg-9ubuntu4+jammy0_amd64.deb ...\n",
            "Unpacking python3-opencv:amd64 (4.5.4+dfsg-9ubuntu4+jammy0) ...\n",
            "Setting up python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Setting up python3-opencv:amd64 (4.5.4+dfsg-9ubuntu4+jammy0) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p include"
      ],
      "metadata": {
        "id": "pqgvj04i8O-i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "g++ add.cpp -o add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df0k0zehXh4f",
        "outputId": "cae59964-03bc-4cef-eee3-25669a439576"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./add"
      ],
      "metadata": {
        "id": "Wkbs5Y3ZX4ul",
        "outputId": "bb35bcf8-c4ea-4697-9d9f-480a21897346",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/utils.h\n",
        "\n",
        "#ifndef UTILS_H\n",
        "#define UTILS_H\n",
        "\n",
        "#include <math.h>\n",
        "#include <opencv2/opencv.hpp>\n",
        "\n",
        "namespace matrix {\n",
        "// Function to compare two matrices\n",
        "inline bool compare_matrices(const float* mat1, const float* mat2, int rows, int cols, float epsilon = 1e-4) {\n",
        "    for (int i = 0; i < rows * cols; ++i) {\n",
        "        if (std::abs(mat1[i] - mat2[i]) > epsilon) {\n",
        "            return false;\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "}\n",
        "\n",
        "namespace utils{\n",
        "// Function to compare two matrices\n",
        "inline bool compare_vectors(const float* vec1, const float* vec2, int size, float epsilon = 1e-4) {\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        if (std::abs(vec1[i] - vec2[i]) > epsilon) {\n",
        "            return false;\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "}\n",
        "\n",
        "namespace imageio {\n",
        "inline cv::Mat readImage(std::string image_path) {\n",
        "    cv::Mat image = cv::imread(image_path, cv::IMREAD_COLOR);\n",
        "\n",
        "    if (image.empty()) {\n",
        "        std::cerr << \"Could not open or find the image at \" << image_path << std::endl;\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    return image;\n",
        "}\n",
        "\n",
        "inline cv::Mat toFloatMat(const cv::Mat& mat) {\n",
        "    cv::Mat float_mat;\n",
        "    if (mat.type() != CV_32F) {\n",
        "        mat.convertTo(float_mat, CV_32F);\n",
        "    } else {\n",
        "        float_mat = mat;\n",
        "    }\n",
        "    return float_mat;\n",
        "}\n",
        "\n",
        "inline void matToFloatArray(const cv::Mat& mat, float* out, size_t size) {\n",
        "    cv::Mat floatMat = toFloatMat(mat);\n",
        "    std::memcpy(out, floatMat.data, size * sizeof(float));\n",
        "}\n",
        "\n",
        "inline cv::Mat floatArrayToMat(const float* floatArray, int width, int height, int channels) {\n",
        "    cv::Mat image(height, width, CV_32FC(channels));\n",
        "    std::memcpy(image.data, floatArray, width * height * channels * sizeof(float));\n",
        "    return image;\n",
        "}\n",
        "\n",
        "inline void writeImage(const float* float_array, int width, int height, int num_channels, std::string output_path) {\n",
        "// convert float array to matrix and write to disk.\n",
        "    cv::Mat restored = imageio::floatArrayToMat(float_array, width, height, num_channels);\n",
        "    bool success = cv::imwrite(output_path, restored);\n",
        "    if (!success) {\n",
        "        std::cerr << \"Could not write image to disk at \" << output_path << std::endl;\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "}\n",
        "\n",
        "#endif // UTILS_H%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh9EXkkCA6RP",
        "outputId": "eaf05e15-6806-4901-a791-eb9001961ca5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing include/utils.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/matrix.h\n",
        "\n",
        "#ifndef MATRIX_H\n",
        "#define MATRIX_H\n",
        "\n",
        "#include <memory>\n",
        "#include <functional>\n",
        "#include <iomanip>\n",
        "\n",
        "struct Matrix {\n",
        "    int height;\n",
        "    int width;\n",
        "    std::unique_ptr<float[]> data;\n",
        "    Matrix(int height_, int width_, std::function<void(float*, int)> init_func)\n",
        "    : height(height_), width(width_), data(std::make_unique<float[]>(height_ * width_)) {\n",
        "        init_func(data.get(), height_ * width_);\n",
        "    }\n",
        "\n",
        "    // copy constructor, deep copies data value.\n",
        "    // reason for this is that we support in-place operations on matrix\n",
        "    // having this just makes it easier to validate the cpu vs gpu implementations.\n",
        "    Matrix(const Matrix& other)\n",
        "    : height(other.height), width(other.width),\n",
        "    data(std::make_unique<float[]>(other.height * other.width)) {\n",
        "        std::copy(other.data.get(), other.data.get() + other.height * other.width, data.get());\n",
        "    }\n",
        "\n",
        "    // TODO: add move semantics\n",
        "\n",
        "    void print() const {\n",
        "        std::cout << std::fixed << std::setprecision(4);\n",
        "        for(int i =0; i < height; ++i) {\n",
        "            for(int j = 0; j < width; ++j) {\n",
        "                std::cout << data[i * width + j] << \" \";\n",
        "            }\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "    }\n",
        "};\n",
        "\n",
        "#endif //MATRIX_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2q_m8kd9nyb",
        "outputId": "b27bf03a-b75a-45ed-ba3e-0bf72765369c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing include/matrix.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/init_utils.h\n",
        "\n",
        "#ifndef INIT_UTILS_H\n",
        "#define INIT_UTILS_H\n",
        "\n",
        "#include <random>\n",
        "\n",
        "inline void random_init(float *array, int size) {\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "\n",
        "    std::uniform_real_distribution<> dist(0.0, 1.0);\n",
        "\n",
        "    for(int i=0; i < size; ++i) {\n",
        "        array[i] = dist(gen);\n",
        "    }\n",
        "}\n",
        "\n",
        "#endif // INIT_UTILS_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByP4V82_-D9O",
        "outputId": "2a02d872-26ea-466b-b0d9-7b529a05998c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing include/init_utils.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/cuda_utils.h\n",
        "\n",
        "#ifndef CUDA_UTILS_H\n",
        "#define CUDA_UTILS_H\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define CUDA_ERROR_CHECK(call)  { \\\n",
        "    cudaError_t error = call; \\\n",
        "    if (error != cudaSuccess) { \\\n",
        "        fprintf(stderr, \"CUDA error in file '%s' in line %i.%s \\n\", \\\n",
        "                __FILE__, __LINE__, cudaGetErrorString(error)); \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    }}\n",
        "\n",
        "#define TIMED_CUDA_FUNCTION() CudaEventTimer(__FUNCTION__)\n",
        "\n",
        "class CudaEventTimer {\n",
        "\n",
        "public:\n",
        "    CudaEventTimer(const char* function_name):\n",
        "    function_name_(function_name) {\n",
        "        cudaEventCreate(&start_);\n",
        "        cudaEventCreate(&stop_);\n",
        "        cudaEventRecord(start_);\n",
        "    }\n",
        "\n",
        "    ~CudaEventTimer() {\n",
        "        cudaEventRecord(stop_);\n",
        "        cudaEventSynchronize(stop_);\n",
        "        float milliseconds = 0.0f;\n",
        "        cudaEventElapsedTime(&milliseconds, start_, stop_);\n",
        "        std::cout << \"CUDA function \" << function_name_ << \" finished in \" << milliseconds << \" ms\" << std::endl;\n",
        "        cudaEventDestroy(start_);\n",
        "        cudaEventDestroy(stop_);\n",
        "\n",
        "    }\n",
        "private:\n",
        "    const char* function_name_;\n",
        "    cudaEvent_t start_, stop_;\n",
        "};\n",
        "\n",
        "#endif // CUDA_UTILS_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UBfiPWF-Vpz",
        "outputId": "40d8217b-15a0-4a10-c82a-398c612cefe3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing include/cuda_utils.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/timing_utils.h\n",
        "\n",
        "#ifndef TIMING_UTILS_H\n",
        "#define TIMING_UTILS_H\n",
        "\n",
        "#include <chrono>\n",
        "#include <string>\n",
        "#include <iostream>\n",
        "\n",
        "#define TIMED_CPU_FUNCTION() timers::FunctionTimer timer(__FUNCTION__)\n",
        "\n",
        "namespace timers {\n",
        "class FunctionTimer {\n",
        "public:\n",
        "    FunctionTimer(std::string function_name) :\n",
        "    function_name_(function_name), start_(std::chrono::high_resolution_clock::now()) {}\n",
        "\n",
        "    ~FunctionTimer() {\n",
        "        auto end = std::chrono::high_resolution_clock::now();\n",
        "        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start_).count();\n",
        "        std::cout << \"CPU function \" << function_name_ << \" finished in \" << duration << \" ms\" <<std::endl;\n",
        "    }\n",
        "\n",
        "private:\n",
        "std::string function_name_;\n",
        "std::chrono::time_point<std::chrono::high_resolution_clock> start_;\n",
        "\n",
        "};\n",
        "}\n",
        "\n",
        "#endif //TIMING_UTILS_H%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QkBMVJw-3Od",
        "outputId": "42d651ae-4241-468d-c2de-dae3c2b0f572"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing include/timing_utils.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/cpu_kernels.h\n",
        "\n",
        "#ifndef CPU_KERNELS_H\n",
        "#define CPU_KERNELS_H\n",
        "\n",
        "#include <vector>\n",
        "\n",
        "void matmul_cpu(const float* a, const float* b, float* c, int M, int K, int N);\n",
        "void conv1d_cpu(const std::vector<float>& matrix, const std::vector<float>& conv_mask,\n",
        "                std::vector<float>& output, int mask_width, int width);\n",
        "\n",
        "void conv2d_cpu(const std::vector<float>& matrix, const std::vector<float>& conv_mask,\n",
        "                std::vector<float>& output, int r, int width, int height);\n",
        "\n",
        "void softmax_cpu(float* mat, int M, int N);\n",
        "\n",
        "\n",
        "#endif // CPU_KERNELS_H%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agXtS2Pw-xQ_",
        "outputId": "0690c6a1-897e-43db-ba94-9a783ebee7b0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing include/cpu_kernels.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cpu_kernels.cpp\n",
        "\n",
        "#include \"cpu_kernels.h\"\n",
        "#include \"timing_utils.h\"\n",
        "\n",
        "void matmul_cpu(const float* a, const float* b, float* c, int M, int K, int N) {\n",
        "    TIMED_CPU_FUNCTION();\n",
        "    for(int row=0; row < M; ++row) {\n",
        "        for(int col = 0; col < N; ++col) {\n",
        "            float value = 0.0f;\n",
        "            for (int k = 0; k < K; ++k) {\n",
        "                value += a[row * K + k] * b[k * N + col];\n",
        "            }\n",
        "            c[row * N + col] = value;\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPtzGQo3-qVq",
        "outputId": "c7cd82de-1770-441e-a94f-738a3bb4d634"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cpu_kernels.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile include/gemm.h\n",
        "\n",
        "#ifndef GEMM_H\n",
        "#define GEMM_H\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void gemm_cuda_tiled(const float* __restrict__  A, const float* __restrict__ B, float* C, int M, int K, int N);\n",
        "\n",
        "\n",
        "#endif // GEMM_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRMXnEDw_rqD",
        "outputId": "a1354111-3a2a-4dc3-9705-f67980753924"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing include/gemm.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gemm.cu\n",
        "\n",
        "#include \"timing_utils.h\"\n",
        "#include \"init_utils.h\"\n",
        "#include \"matrix.h\"\n",
        "#include \"cuda_utils.h\"\n",
        "#include \"gemm.h\"\n",
        "#include \"cpu_kernels.h\"\n",
        "#include \"utils.h\"\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iomanip>\n",
        "\n",
        "__global__ void gemm_cuda_tiled(const float* __restrict__  a, const float* __restrict__ b,\n",
        "                                float* c, int M, int K, int N) {\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "\n",
        "    int row = by * TILE_WIDTH + ty;\n",
        "    int col = bx * TILE_WIDTH + tx;\n",
        "\n",
        "    __shared__ float a_shared[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ float b_shared[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "    float p_value = 0.0f;\n",
        "    for(int ph = 0; ph < (K + TILE_WIDTH - 1)/ TILE_WIDTH; ++ph) {\n",
        "        if (row < M && ph * TILE_WIDTH + tx < K) {\n",
        "            a_shared[ty][tx] = a[row * K + ph * TILE_WIDTH + tx];\n",
        "        } else {\n",
        "            a_shared[ty][tx] = 0.0f;\n",
        "        }\n",
        "        if(ph * TILE_WIDTH + ty < K && col < N) {\n",
        "            b_shared[ty][tx] = b[(ph * TILE_WIDTH + ty) * N + col];\n",
        "        } else {\n",
        "            b_shared[ty][tx] = 0.0f;\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for(int i = 0; i < TILE_WIDTH; ++i) {\n",
        "            p_value += a_shared[ty][i] * b_shared[i][tx];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(row < M && col < N) {\n",
        "        c[row * N + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void gemm_cuda_register_tiled(float* a, float* b, float* c, int M, int K, int N) {\n",
        "    constexpr int T = 64;\n",
        "    constexpr int U = 16;\n",
        "    constexpr int S = T / U;\n",
        "    __shared__ float b_shared[S * U];\n",
        "    float a_reg[S];\n",
        "    float c_reg[U] = {0.0f}; // each thread calculates U values.\n",
        "    // global row and global column index for current thread.\n",
        "    int row = blockIdx.y * T + threadIdx.y;\n",
        "    int col_base = blockIdx.x * U;\n",
        "\n",
        "    for(int ph = 0; ph < (K + S - 1) / S; ++ph) {\n",
        "        // load S x U tile of B in shared memory\n",
        "        if(threadIdx.y < S) {\n",
        "            for(int u = 0; u < U; ++u) {\n",
        "                int col = col_base + u;\n",
        "                if(col < N && (ph * S + threadIdx.y) < K) {\n",
        "                    b_shared[threadIdx.y * U + u] = b[(ph * S + threadIdx.y) * N + col];\n",
        "                } else {\n",
        "                    b_shared[threadIdx.y * U + u] = 0.0f;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        // load S elements of A into register\n",
        "        for(int s = 0; s < S; ++s) {\n",
        "            if(row < M && (ph * S + s) < K) {\n",
        "                a_reg[s] = a[row * K + (ph * S + s)];\n",
        "            } else {\n",
        "                a_reg[s] = 0.0f;\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        // perform computation for current tile\n",
        "        //#pragma unroll\n",
        "        for(int u = 0; u < U; ++u) {\n",
        "            //#pragma unroll\n",
        "            for(int s = 0; s < S; ++s) {\n",
        "                c_reg[u] += a_reg[s] * b_shared[s * U + u];\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    for(int u = 0; u< U; ++u) {\n",
        "        int col = col_base + u;\n",
        "        if (row < M && col < N) {\n",
        "            c[row * N + col] = c_reg[u];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void gemm_kernel_launch(float* mat1_d, float* mat2_d, float* out_d, int M, int K, int N) {\n",
        "    TIMED_CUDA_FUNCTION();\n",
        "    int block_size_x = 1; //TILE_WIDTH;\n",
        "    int block_size_y = 64; //TILE_WIDTH;\n",
        "\n",
        "    dim3 threads_per_block(block_size_x,\n",
        "                           block_size_y);\n",
        "\n",
        "    dim3 blocks_per_grid((N + 16 - 1) / 16,\n",
        "                         (M + 64 - 1) / 64);\n",
        "\n",
        "    gemm_cuda_register_tiled<<<blocks_per_grid, threads_per_block>>>(mat1_d, mat2_d, out_d, M, K, N);\n",
        "    cudaDeviceSynchronize();\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    int M = 2048;\n",
        "    int K = 1024;\n",
        "    int N = 2048;\n",
        "    Matrix mat1_h(M, K, random_init);\n",
        "    Matrix mat2_h(K, N, random_init);\n",
        "    float* out_h = new float[M * N];\n",
        "    float* out_cpu = new float[M * N];\n",
        "    matmul_cpu(mat1_h.data.get(), mat2_h.data.get(), out_cpu, M, K, N);\n",
        "    float *mat1_d, *mat2_d, *out_d;\n",
        "\n",
        "    CUDA_ERROR_CHECK(cudaMalloc((void**) &mat1_d, M * K * sizeof(float)));\n",
        "    CUDA_ERROR_CHECK(cudaMalloc((void**) &mat2_d, K * N * sizeof(float)));\n",
        "    CUDA_ERROR_CHECK(cudaMalloc((void**) &out_d, M * N * sizeof(float)));\n",
        "\n",
        "    CUDA_ERROR_CHECK(cudaMemcpy(mat1_d, mat1_h.data.get(), M * K * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_ERROR_CHECK(cudaMemcpy(mat2_d, mat2_h.data.get(), K * N * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    gemm_kernel_launch(mat1_d, mat2_d, out_d, M, K, N);\n",
        "\n",
        "    CUDA_ERROR_CHECK(cudaMemcpy(out_h, out_d, M * N * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    if (matrix::compare_matrices(out_h, out_cpu, M, N)) {\n",
        "        std::cout << \"CUDA kernel's result matches the CPU result.\" << std::endl;\n",
        "    } else {\n",
        "        std::cerr << \"CUDA kernel's result does NOT match the CPU result.\" << std::endl;\n",
        "    }\n",
        "\n",
        "    delete [] out_h;\n",
        "    delete [] out_cpu;\n",
        "    cudaFree(mat1_d);\n",
        "    cudaFree(mat2_d);\n",
        "    cudaFree(out_d);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "P1GDyYs4X7LR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc4f329-93a5-44b8-ea46-d214bcef8b71"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting gemm.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -I/usr/include/opencv4 -I./include -L/usr/lib gemm.cu cpu_kernels.cpp -o gemm `pkg-config --cflags --libs opencv4` -diag-suppress=611"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL2yVACy_F6w",
        "outputId": "8757902d-57d3-4d25-d697-922c079b04e8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./gemm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyxU_4FzDWxa",
        "outputId": "ceedd503-b55d-455f-97a1-134962c34eec"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU function matmul_cpu finished in 30331 ms\n",
            "CUDA function gemm_kernel_launch finished in 0.004736 ms\n",
            "CUDA kernel's result matches the CPU result.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "With #pragma unroll:\n",
        "\n",
        "\n",
        "```\n",
        "CPU function matmul_cpu finished in 30010 ms\n",
        "CUDA function gemm_kernel_launch finished in 0.004768 ms\n",
        "CUDA kernel's result matches the CPU result.\n",
        "```\n",
        "\n",
        "Without #pragma unroll:\n",
        "\n",
        "\n",
        "```\n",
        "CPU function matmul_cpu finished in 30331 ms\n",
        "CUDA function gemm_kernel_launch finished in 0.004736 ms\n",
        "CUDA kernel's result matches the CPU result.\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xZhMRAHkBLO2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqyPHrEyDsyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}